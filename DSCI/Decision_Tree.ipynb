{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python386jvsc74a57bd0084b600058337c1ed128ca8083189dc1e4acdaba21b28d93c78c8c5801a2baae",
      "display_name": "Python 3.8.6 64-bit"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6-final"
    },
    "colab": {
      "name": "Decision Tree.ipynb",
      "provenance": []
    },
    "metadata": {
      "interpreter": {
        "hash": "084b600058337c1ed128ca8083189dc1e4acdaba21b28d93c78c8c5801a2baae"
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZQbnIBRghXc",
        "outputId": "206f836a-c4b5-4f6b-f4d0-ef9cdd5cf25e"
      },
      "source": [
        "# Run this program on your local python\n",
        "# interpreter, provided you have installed\n",
        "# the required libraries.\n",
        "\n",
        "# Importing the required packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Function importing Dataset\n",
        "def importdata():\n",
        "\t#balance_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/balance-scale/balance-scale.data',\n",
        "\t#sep= ',', header = None)\n",
        "\tnames = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
        "\tbalance_data = pd.read_csv('iris.data',names=names)\n",
        "\t\n",
        "\t# Printing the dataswet shape\n",
        "\tprint (\"Dataset Length: \", len(balance_data))\n",
        "\tprint (\"Dataset Shape: \", balance_data.shape)\n",
        "\t\n",
        "\t# Printing the dataset obseravtions\n",
        "\tprint (\"Dataset: \",balance_data.head())\n",
        "\treturn balance_data\n",
        "\n",
        "# Function to split the dataset\n",
        "def splitdataset(balance_data):\n",
        "\n",
        "\t# Separating the target variable\n",
        "\tX = balance_data.values[:, 0:4]\n",
        "\tY = balance_data.values[:, 4]\n",
        "\n",
        "\t# Splitting the dataset into train and test\n",
        "\tX_train, X_test, y_train, y_test = train_test_split(\n",
        "\tX, Y, test_size = 0.3, random_state = 100)\n",
        "\t\n",
        "\treturn X, Y, X_train, X_test, y_train, y_test\n",
        "\t\n",
        "# Function to perform training with giniIndex.\n",
        "def train_using_gini(X_train, X_test, y_train):\n",
        "\n",
        "\t# Creating the classifier object\n",
        "\tclf_gini = DecisionTreeClassifier(criterion = \"gini\",\n",
        "\t\t\trandom_state = 100,max_depth=3, min_samples_leaf=5)\n",
        "\n",
        "\t# Performing training\n",
        "\tclf_gini.fit(X_train, y_train)\n",
        "\treturn clf_gini\n",
        "\t\n",
        "# Function to perform training with entropy.\n",
        "def tarin_using_entropy(X_train, X_test, y_train):\n",
        "\n",
        "\t# Decision tree with entropy\n",
        "\tclf_entropy = DecisionTreeClassifier(\n",
        "\t\t\tcriterion = \"entropy\", random_state = 100,\n",
        "\t\t\tmax_depth = 3, min_samples_leaf = 5)\n",
        "\n",
        "\t# Performing training\n",
        "\tclf_entropy.fit(X_train, y_train)\n",
        "\treturn clf_entropy\n",
        "\n",
        "\n",
        "# Function to make predictions\n",
        "def prediction(X_test, clf_object):\n",
        "\n",
        "\t# Predicton on test with giniIndex\n",
        "\ty_pred = clf_object.predict(X_test)\n",
        "\tprint(\"Predicted values:\")\n",
        "\tprint(y_pred)\n",
        "\treturn y_pred\n",
        "\t\n",
        "# Function to calculate accuracy\n",
        "def cal_accuracy(y_test, y_pred):\n",
        "\t\n",
        "\tprint(\"Confusion Matrix: \",\n",
        "\t\tconfusion_matrix(y_test, y_pred))\n",
        "\t\n",
        "\tprint (\"Accuracy : \",\n",
        "\taccuracy_score(y_test,y_pred)*100)\n",
        "\t\n",
        "\tprint(\"Report : \",\n",
        "\tclassification_report(y_test, y_pred))\n",
        "\n",
        "# Driver code\n",
        "def main():\n",
        "\t\n",
        "\t# Building Phase\n",
        "\tdata = importdata()\n",
        "\tX, Y, X_train, X_test, y_train, y_test = splitdataset(data)\n",
        "\tclf_gini = train_using_gini(X_train, X_test, y_train)\n",
        "\tclf_entropy = tarin_using_entropy(X_train, X_test, y_train)\n",
        "\t\n",
        "\t# Operational Phase\n",
        "\tprint(\"Results Using Gini Index:\")\n",
        "\t\n",
        "\t# Prediction using gini\n",
        "\ty_pred_gini = prediction(X_test, clf_gini)\n",
        "\tcal_accuracy(y_test, y_pred_gini)\n",
        "\t\n",
        "\tprint(\"Results Using Entropy:\")\n",
        "\t# Prediction using entropy\n",
        "\ty_pred_entropy = prediction(X_test, clf_entropy)\n",
        "\tcal_accuracy(y_test, y_pred_entropy)\n",
        "\t\n",
        "\t\n",
        "# Calling main function\n",
        "if __name__==\"__main__\":\n",
        "\tmain()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Length:  150\nDataset Shape:  (150, 5)\nDataset:     sepal-length  sepal-width  petal-length  petal-width        class\n0           5.1          3.5           1.4          0.2  Iris-setosa\n1           4.9          3.0           1.4          0.2  Iris-setosa\n2           4.7          3.2           1.3          0.2  Iris-setosa\n3           4.6          3.1           1.5          0.2  Iris-setosa\n4           5.0          3.6           1.4          0.2  Iris-setosa\nResults Using Gini Index:\nPredicted values:\n['Iris-virginica' 'Iris-setosa' 'Iris-virginica' 'Iris-setosa'\n 'Iris-virginica' 'Iris-virginica' 'Iris-setosa' 'Iris-setosa'\n 'Iris-virginica' 'Iris-setosa' 'Iris-setosa' 'Iris-virginica'\n 'Iris-setosa' 'Iris-setosa' 'Iris-virginica' 'Iris-versicolor'\n 'Iris-versicolor' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n 'Iris-virginica' 'Iris-setosa' 'Iris-virginica' 'Iris-setosa'\n 'Iris-versicolor' 'Iris-virginica' 'Iris-versicolor' 'Iris-setosa'\n 'Iris-versicolor' 'Iris-virginica' 'Iris-versicolor' 'Iris-versicolor'\n 'Iris-versicolor' 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor'\n 'Iris-setosa' 'Iris-versicolor' 'Iris-virginica' 'Iris-virginica'\n 'Iris-setosa' 'Iris-versicolor' 'Iris-virginica' 'Iris-virginica'\n 'Iris-setosa']\nConfusion Matrix:  [[16  0  0]\n [ 0 10  1]\n [ 0  1 17]]\nAccuracy :  95.55555555555556\nReport :                   precision    recall  f1-score   support\n\n    Iris-setosa       1.00      1.00      1.00        16\nIris-versicolor       0.91      0.91      0.91        11\n Iris-virginica       0.94      0.94      0.94        18\n\n       accuracy                           0.96        45\n      macro avg       0.95      0.95      0.95        45\n   weighted avg       0.96      0.96      0.96        45\n\nResults Using Entropy:\nPredicted values:\n['Iris-virginica' 'Iris-setosa' 'Iris-virginica' 'Iris-setosa'\n 'Iris-virginica' 'Iris-virginica' 'Iris-setosa' 'Iris-setosa'\n 'Iris-virginica' 'Iris-setosa' 'Iris-setosa' 'Iris-virginica'\n 'Iris-setosa' 'Iris-setosa' 'Iris-virginica' 'Iris-versicolor'\n 'Iris-versicolor' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n 'Iris-virginica' 'Iris-setosa' 'Iris-virginica' 'Iris-setosa'\n 'Iris-versicolor' 'Iris-virginica' 'Iris-versicolor' 'Iris-setosa'\n 'Iris-versicolor' 'Iris-virginica' 'Iris-versicolor' 'Iris-versicolor'\n 'Iris-versicolor' 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor'\n 'Iris-setosa' 'Iris-versicolor' 'Iris-virginica' 'Iris-virginica'\n 'Iris-setosa' 'Iris-versicolor' 'Iris-virginica' 'Iris-virginica'\n 'Iris-setosa']\nConfusion Matrix:  [[16  0  0]\n [ 0 10  1]\n [ 0  1 17]]\nAccuracy :  95.55555555555556\nReport :                   precision    recall  f1-score   support\n\n    Iris-setosa       1.00      1.00      1.00        16\nIris-versicolor       0.91      0.91      0.91        11\n Iris-virginica       0.94      0.94      0.94        18\n\n       accuracy                           0.96        45\n      macro avg       0.95      0.95      0.95        45\n   weighted avg       0.96      0.96      0.96        45\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hn80URpkghZQ",
        "outputId": "a9880725-ca99-49b9-a118-7e2145bbccba"
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# import some data to play with\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "\n",
        "#List built in datasets\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Squ8quyghZU"
      },
      "source": [
        "\n",
        "from datasets import list_datasets\n",
        "datasets_list = list_datasets\n",
        "\n",
        "len(datasets_list)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'datasets'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-8-3d666b3bf537>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlist_datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdatasets_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist_datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasets_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpcYfVQdghZV",
        "outputId": "5fa5a212-0c25-4c4b-fd60-adb8f8b436f3"
      },
      "source": [
        "from sklearn import datasets  #Import datasets module from scikit-learn\n",
        "diabetes = datasets.load_diabetes()  \n",
        "\n",
        "#diabetes.head()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ess9ciiAghZW",
        "outputId": "27d0dc3f-10ef-4200-ecd5-6dce28c0744e"
      },
      "source": [
        "digits = datasets.load_Advertising()\n",
        "digits"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'sklearn.datasets' has no attribute 'load_Advertising'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-12-cc7164418666>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdigits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_Advertising\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdigits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: module 'sklearn.datasets' has no attribute 'load_Advertising'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8h2ezChighZX",
        "outputId": "06b48a93-5e2f-480f-91d9-97b78aeac27f"
      },
      "source": [
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "dir(datasets)\n",
        "digits = datasets.load_diabetes()\n",
        "#pd.read_csv(\"diabetes\")\n",
        "digits"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
              "          0.01990842, -0.01764613],\n",
              "        [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
              "         -0.06832974, -0.09220405],\n",
              "        [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
              "          0.00286377, -0.02593034],\n",
              "        ...,\n",
              "        [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
              "         -0.04687948,  0.01549073],\n",
              "        [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
              "          0.04452837, -0.02593034],\n",
              "        [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
              "         -0.00421986,  0.00306441]]),\n",
              " 'target': array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
              "         69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
              "         68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
              "         87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
              "        259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
              "        128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
              "        150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
              "        200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
              "         42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
              "         83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
              "        104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
              "        173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
              "        107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
              "         60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
              "        197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
              "         59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
              "        237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
              "        143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
              "        142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
              "         77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
              "         78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
              "        154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
              "         71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
              "        150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
              "        145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
              "         94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
              "         60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
              "         31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
              "        114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
              "        191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
              "        244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
              "        263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
              "         77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
              "         58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
              "        140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
              "        219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
              "         43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
              "        140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
              "         84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
              "         94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
              "        220.,  57.]),\n",
              " 'frame': None,\n",
              " 'DESCR': '.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n  :Number of Instances: 442\\n\\n  :Number of Attributes: First 10 columns are numeric predictive values\\n\\n  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n  :Attribute Information:\\n      - age     age in years\\n      - sex\\n      - bmi     body mass index\\n      - bp      average blood pressure\\n      - s1      tc, T-Cells (a type of white blood cells)\\n      - s2      ldl, low-density lipoproteins\\n      - s3      hdl, high-density lipoproteins\\n      - s4      tch, thyroid stimulating hormone\\n      - s5      ltg, lamotrigine\\n      - s6      glu, blood sugar level\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttps://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)',\n",
              " 'feature_names': ['age',\n",
              "  'sex',\n",
              "  'bmi',\n",
              "  'bp',\n",
              "  's1',\n",
              "  's2',\n",
              "  's3',\n",
              "  's4',\n",
              "  's5',\n",
              "  's6'],\n",
              " 'data_filename': 'C:\\\\Users\\\\Nouman\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\diabetes_data.csv.gz',\n",
              " 'target_filename': 'C:\\\\Users\\\\Nouman\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\diabetes_target.csv.gz'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk1o_zcFghZY"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgpce-LmghZZ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}